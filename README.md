# NLP-Padding

Padding as we know all the neural networks needs to have the inputs that should be in similar shape and size. When we pre-process the texts and use the texts as an inputs 
for our Model. Note that not all the sequences have the same length, as we can say naturally some of the sequences are long in lengths and some are short. 
Where we know that we need to have the inputs with the same size, now here padding comes into picture. The inputs should be in same size at that time padding is necessary.
